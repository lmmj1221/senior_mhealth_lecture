
"""
ì‹¤ì œ API ì—°ë™ ëª¨ë“ˆ
Google Cloud Speech APIì™€ Grok(XAI) API ì—°ë™ (GPT-4o, Gemini fallback)
Firebase Storage í†µí•© ë° í™”ì ë¶„ë¦¬ ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„
"""

import os
import asyncio
import logging
import json
import base64
import tempfile
import io
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import time
from datetime import datetime
import hashlib

from google.cloud import speech
from google.cloud import storage
from google.oauth2 import service_account
from google.api_core import retry
from google.api_core.exceptions import GoogleAPIError
import numpy as np
import librosa
import soundfile as sf
import openai
from openai import OpenAI  # OpenAI 1.51.0ì—ì„œëŠ” ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
import google.generativeai as genai
from .firebase_storage_connector import FirebaseStorageConnector

logger = logging.getLogger(__name__)


class GoogleCloudConnector:
    """Google Cloud API í†µí•© ì»¤ë„¥í„°"""

    def __init__(self, credentials_path: Optional[str] = None, project_id: Optional[str] = None):
        """ì´ˆê¸°í™”"""
        self.credentials_path = credentials_path or os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
        self.project_id = project_id or os.getenv('GCP_PROJECT_ID')


class GoogleCloudSpeechConnector:
    """Google Cloud Speech API ì—°ë™ - í™”ì ë¶„ë¦¬ ê¸°ëŠ¥ ì™„ì „ êµ¬í˜„"""

    def __init__(self, credentials_path: Optional[str] = None, project_id: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            credentials_path: ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ
            project_id: GCP í”„ë¡œì íŠ¸ ID
        """
        self.project_id = project_id or os.getenv('GCP_PROJECT_ID', 'senior-mhealth-472007')

        # ì¸ì¦ ì„¤ì •
        if credentials_path and Path(credentials_path).exists():
            credentials = service_account.Credentials.from_service_account_file(
                credentials_path
            )
            self.client = speech.SpeechClient(credentials=credentials)
            self.storage_client = storage.Client(credentials=credentials, project=self.project_id)
        else:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ
            self.client = speech.SpeechClient()
            self.storage_client = storage.Client(project=self.project_id)

        # Firebase Storage ì—°ë™
        self.storage_connector = FirebaseStorageConnector(credentials_path)

        # Google Cloud Storage ë²„í‚· ì„¤ì •
        self.bucket_name = os.getenv('GCS_BUCKET_NAME', 'senior-mhealth-472007.firebasestorage.app')

        # Long Running ì‘ì—… ìƒíƒœ ìºì‹œ
        self.operation_cache = {}

        logger.info(f"Google Cloud Speech API ì—°ë™ ì´ˆê¸°í™” ì™„ë£Œ - Project: {self.project_id}")

    async def transcribe_with_diarization(
        self,
        audio_path: str,
        language_code: str = 'ko-KR',
        enable_word_confidence: bool = True,
        use_enhanced_model: bool = True
    ) -> Dict[str, Any]:
        """
        í™”ì ë¶„ë¦¬ë¥¼ í¬í•¨í•œ ìŒì„± ì¸ì‹ (3ë¶„ ì´ìƒ ê¸´ ì˜¤ë””ì˜¤ ìµœì í™”)

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” Firebase Storage URL)
            language_code: ì–¸ì–´ ì½”ë“œ
            enable_word_confidence: ë‹¨ì–´ë³„ ì‹ ë¢°ë„ í¬í•¨ ì—¬ë¶€
            use_enhanced_model: í–¥ìƒëœ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ì „ì‚¬ ê²°ê³¼ with í™”ì ë¶„ë¦¬ ì •ë³´
        """
        try:
            start_time = time.time()

            # 1. ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            audio_metadata = self._get_audio_metadata(audio_path)
            duration = audio_metadata.get('duration', 0)
            sample_rate = audio_metadata.get('sample_rate', 16000)

            logger.info(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘: {duration:.1f}ì´ˆ, {sample_rate}Hz")

            # 2. Firebase Storageì— ì—…ë¡œë“œ (3ë¶„ ì´ìƒì€ í•„ìˆ˜)
            if duration >= 180 or not os.path.exists(audio_path):
                # Firebase Storage ë˜ëŠ” GCSì— ì—…ë¡œë“œ
                gs_uri = await self._upload_to_storage(audio_path)
                logger.info(f"ì˜¤ë””ì˜¤ íŒŒì¼ Storage ì—…ë¡œë“œ ì™„ë£Œ: {gs_uri}")
            else:
                # ì§§ì€ íŒŒì¼ë„ ì¼ê´€ì„±ì„ ìœ„í•´ Storage ì‚¬ìš© ê¶Œì¥
                gs_uri = await self._upload_to_storage(audio_path)

            # 3. Speech Recognition ì„¤ì • êµ¬ì„±
            # ë³€í™˜ëœ LINEAR16 ì˜¤ë””ì˜¤ëŠ” í•­ìƒ 16000Hz
            config = self._build_recognition_config(
                sample_rate=16000,  # LINEAR16 ë³€í™˜ í›„ í•­ìƒ 16000Hz
                language_code=language_code,
                enable_word_confidence=enable_word_confidence,
                use_enhanced_model=use_enhanced_model,
                enable_diarization=True
            )

            # 4. Long Running API ì‹¤í–‰ (3ë¶„ ì´ìƒ í•„ìˆ˜)
            operation = await self._start_long_running_recognition(gs_uri, config)

            # 5. ì‘ì—… ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
            result = await self._wait_for_operation(operation)

            # 6. í™”ì ë¶„ë¦¬ ê²°ê³¼ ì²˜ë¦¬
            processed_result = self._process_diarization_result(result, audio_metadata)

            # 7. í™”ì ì‹ ë¢°ë„ ë° ê²€ì¦
            processed_result = self._validate_speaker_separation(processed_result)

            # 8. Storage ì •ë¦¬ (ì„ì‹œ íŒŒì¼)
            if 'temp/' in gs_uri:
                await self._cleanup_storage(gs_uri)

            processing_time = time.time() - start_time
            processed_result['metadata'] = {
                'processing_time': processing_time,
                'audio_duration': duration,
                'sample_rate': 16000,  # ë³€í™˜ëœ ìƒ˜í”Œë ˆì´íŠ¸
                'original_sample_rate': sample_rate,
                'model_used': 'enhanced' if use_enhanced_model else 'standard',
                'api_type': 'long_running'
            }

            logger.info(f"STT ë° í™”ì ë¶„ë¦¬ ì™„ë£Œ - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            return processed_result

        except Exception as e:
            logger.error(f"Google Cloud Speech API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'segments': [],
                'transcript': ''
            }

    def _get_audio_metadata(self, audio_path: str) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            # librosaë¡œ ì˜¤ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
            y, sr = librosa.load(audio_path, sr=None, mono=True)
            duration = len(y) / sr

            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            metadata = {
                'duration': duration,
                'sample_rate': sr,
                'channels': 1,  # monoë¡œ ë³€í™˜
                'total_samples': len(y),
                'file_size': os.path.getsize(audio_path) if os.path.exists(audio_path) else 0
            }

            # ì˜¤ë””ì˜¤ í’ˆì§ˆ í‰ê°€
            if len(y) > 0:
                metadata['snr'] = self._calculate_snr(y)
                metadata['energy_mean'] = np.mean(np.abs(y))
                metadata['energy_std'] = np.std(np.abs(y))

            return metadata

        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {'duration': 0, 'sample_rate': 16000}

    def _calculate_snr(self, audio: np.ndarray) -> float:
        """ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ SNR ì¶”ì •
            signal_power = np.mean(audio ** 2)
            noise_floor = np.percentile(np.abs(audio), 10) ** 2

            if noise_floor > 0:
                snr = 10 * np.log10(signal_power / noise_floor)
                return max(0, min(snr, 40))  # 0-40dB ë²”ìœ„
            return 20.0  # ê¸°ë³¸ê°’

        except:
            return 20.0

    async def _upload_to_storage(self, audio_path: str) -> str:
        """Firebase Storage ë˜ëŠ” Google Cloud Storageì— ì—…ë¡œë“œ (PCM ë³€í™˜ í¬í•¨)"""
        try:
            # íŒŒì¼ í•´ì‹œë¡œ ì¤‘ë³µ ì²´í¬
            file_hash = self._get_file_hash(audio_path)

            # ì˜¤ë””ì˜¤ í˜•ì‹ ë³€í™˜ (PCM LINEAR16ìœ¼ë¡œ)
            converted_path = await self._convert_to_linear16(audio_path)

            # Firebase Storage ìš°ì„  ì‹œë„
            if self.storage_connector:
                gs_uri, blob_name = self.storage_connector.upload_temp_audio(converted_path)

                # Firebase StorageëŠ” ë¡œì»¬ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ GCS URI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                if not gs_uri.startswith('gs://'):
                    # Google Cloud Storageì— ì§ì ‘ ì—…ë¡œë“œ
                    gs_uri = await self._upload_to_gcs(converted_path, file_hash)

                # ì„ì‹œ ë³€í™˜ íŒŒì¼ ì‚­ì œ
                if converted_path != audio_path:
                    os.unlink(converted_path)

                return gs_uri
            else:
                # Google Cloud Storage ì§ì ‘ ì—…ë¡œë“œ
                gs_uri = await self._upload_to_gcs(converted_path, file_hash)

                # ì„ì‹œ ë³€í™˜ íŒŒì¼ ì‚­ì œ
                if converted_path != audio_path:
                    os.unlink(converted_path)

                return gs_uri

        except Exception as e:
            logger.error(f"Storage ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    async def _upload_to_gcs(self, audio_path: str, file_hash: str) -> str:
        """Google Cloud Storageì— ì§ì ‘ ì—…ë¡œë“œ"""
        try:
            bucket = self.storage_client.bucket(self.bucket_name)

            # ê³ ìœ í•œ blob ì´ë¦„ ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = Path(audio_path).name
            blob_name = f"audio/temp/{timestamp}_{file_hash[:8]}_{filename}"

            blob = bucket.blob(blob_name)

            # ì—…ë¡œë“œ (ì¬ì‹œë„ í¬í•¨)
            with open(audio_path, 'rb') as audio_file:
                blob.upload_from_file(
                    audio_file,
                    retry=retry.Retry(deadline=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                )

            gs_uri = f"gs://{self.bucket_name}/{blob_name}"
            logger.info(f"GCS ì—…ë¡œë“œ ì™„ë£Œ: {gs_uri}")

            return gs_uri

        except Exception as e:
            logger.error(f"GCS ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def _get_file_hash(self, file_path: str) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    async def _convert_to_linear16(self, audio_path: str) -> str:
        """ì˜¤ë””ì˜¤ë¥¼ LINEAR16 PCM í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # ì´ë¯¸ WAV íŒŒì¼ì¸ì§€ í™•ì¸
            if audio_path.lower().endswith('.wav'):
                # WAV íŒŒì¼ì´ì–´ë„ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
                audio, sr = librosa.load(audio_path, sr=16000, mono=True)

                # 16-bit PCMìœ¼ë¡œ ë³€í™˜
                audio_16bit = (audio * 32767).astype(np.int16)

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_path = audio_path.replace('.wav', '_linear16.wav')
                sf.write(temp_path, audio_16bit, 16000, subtype='PCM_16')

                logger.info(f"WAV íŒŒì¼ì„ LINEAR16 PCMìœ¼ë¡œ ë³€í™˜: {temp_path}")
                return temp_path
            else:
                # m4a, mp3 ë“± ë‹¤ë¥¸ í˜•ì‹
                logger.info(f"ì˜¤ë””ì˜¤ í˜•ì‹ ë³€í™˜ ì‹œì‘: {audio_path}")

                # librosaë¡œ ë¡œë“œ (ìë™ìœ¼ë¡œ ë””ì½”ë”©)
                audio, sr = librosa.load(audio_path, sr=16000, mono=True)

                # 16-bit PCMìœ¼ë¡œ ë³€í™˜
                audio_16bit = (audio * 32767).astype(np.int16)

                # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥
                temp_path = audio_path + '_linear16.wav'
                sf.write(temp_path, audio_16bit, 16000, subtype='PCM_16')

                logger.info(f"ì˜¤ë””ì˜¤ë¥¼ LINEAR16 PCMìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ: {temp_path}")
                return temp_path

        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ íŒŒì¼ ë°˜í™˜
            return audio_path

    def _build_recognition_config(
        self,
        sample_rate: int,
        language_code: str,
        enable_word_confidence: bool,
        use_enhanced_model: bool,
        enable_diarization: bool
    ) -> speech.RecognitionConfig:
        """Speech Recognition ì„¤ì • êµ¬ì„±"""

        # í™”ì ë¶„ë¦¬ ì„¤ì • (2ëª… ê³ ì •)
        diarization_config = speech.SpeakerDiarizationConfig(
            enable_speaker_diarization=True,
            min_speaker_count=2,
            max_speaker_count=2,
        )

        # í™”ìë¶„ë¦¬ ë””ë²„ê¹… ë¡œê·¸
        logger.info(f"ğŸ¯ í™”ìë¶„ë¦¬ ì„¤ì •: enable={enable_diarization}, min_speakers=2, max_speakers=2")

        # ê¸°ë³¸ ì„¤ì •
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=sample_rate,
            language_code=language_code,
            enable_word_time_offsets=True,
            enable_word_confidence=enable_word_confidence,
            enable_automatic_punctuation=True,
            diarization_config=diarization_config if enable_diarization else None,
            model='latest_long' if use_enhanced_model else 'default',
            use_enhanced=use_enhanced_model,
            # í•œêµ­ì–´ íŠ¹í™” ì„¤ì •
            speech_contexts=[
                speech.SpeechContext(
                    phrases=[
                        "ìš°ìš¸", "ë¶ˆì•ˆ", "ìŠ¤íŠ¸ë ˆìŠ¤", "ìˆ˜ë©´", "í”¼ê³¤",
                        "í• ë¨¸ë‹ˆ", "í• ì•„ë²„ì§€", "ì–´ë¥´ì‹ ", "ì†ì", "ì†ë…€"
                    ],
                    boost=10.0
                )
            ],
            metadata=speech.RecognitionMetadata(
                interaction_type=speech.RecognitionMetadata.InteractionType.DISCUSSION,
                recording_device_type=speech.RecognitionMetadata.RecordingDeviceType.OTHER_INDOOR_DEVICE,
                original_media_type=speech.RecognitionMetadata.OriginalMediaType.AUDIO,
            )
        )

        return config

    async def _start_long_running_recognition(
        self,
        gs_uri: str,
        config: speech.RecognitionConfig
    ) -> Any:
        """Long Running Recognition ì‹œì‘"""

        audio = speech.RecognitionAudio(uri=gs_uri)

        # Long Running ì‘ì—… ì‹œì‘
        operation = self.client.long_running_recognize(
            config=config,
            audio=audio,
            retry=retry.Retry(deadline=600)  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        # operation ì •ë³´ ë¡œê¹… (name ì†ì„±ì´ ì—†ì–´ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        operation_id = str(id(operation))  # ê°ì²´ ID ì‚¬ìš©
        logger.info(f"Long Running Recognition ì‹œì‘ - Operation ID: {operation_id}")

        # ì‘ì—… ì •ë³´ ìºì‹± (name ëŒ€ì‹  ê°ì²´ ID ì‚¬ìš©)
        self.operation_cache[operation_id] = {
            'started_at': datetime.now(),
            'gs_uri': gs_uri,
            'operation': operation  # operation ê°ì²´ ìì²´ë¥¼ ì €ì¥
        }

        return operation

    async def _wait_for_operation(self, operation: Any, poll_interval: int = 5) -> Any:
        """Long Running ì‘ì—… ì™„ë£Œ ëŒ€ê¸°"""

        logger.info("ì‘ì—… ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ì‹œì‘...")

        try:
            # result() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ë£Œ ëŒ€ê¸° (ê¶Œì¥ ë°©ì‹)
            # timeoutì„ ì„¤ì •í•˜ì—¬ ìµœëŒ€ 30ë¶„ê¹Œì§€ ëŒ€ê¸°
            result = operation.result(timeout=1800)  # 30ë¶„ íƒ€ì„ì•„ì›ƒ
            logger.info("Long Running Recognition ì™„ë£Œ")
            return result

        except Exception as e:
            logger.error(f"Speech API ì‘ì—… ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
            # ëŒ€ì²´ ë°©ë²•: í´ë§ì„ í†µí•œ ìˆ˜ë™ ëŒ€ê¸°
            try:
                start_time = time.time()
                while True:
                    # done() ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ ì‚¬ìš©
                    if hasattr(operation, 'done') and callable(operation.done):
                        if operation.done():
                            break

                    # íƒ€ì„ì•„ì›ƒ ì²´í¬
                    if time.time() - start_time > 1800:
                        raise TimeoutError("STT ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (30ë¶„)")

                    await asyncio.sleep(poll_interval)

                # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                if hasattr(operation, 'result'):
                    result = operation.result()
                    logger.info("Long Running Recognition ì™„ë£Œ (í´ë°± ë°©ì‹)")
                    return result
                else:
                    raise RuntimeError("Operation ê°ì²´ì— result() ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")

            except Exception as fallback_error:
                logger.error(f"í´ë°± ë°©ì‹ë„ ì‹¤íŒ¨: {fallback_error}")
                raise

    def _process_diarization_result(
        self,
        result: Any,
        audio_metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í™”ì ë¶„ë¦¬ ê²°ê³¼ ì²˜ë¦¬"""

        segments = []
        full_transcript = []
        speaker_stats = {}

        # ğŸ” ìƒì„¸ ë””ë²„ê¹…: API ì‘ë‹µ êµ¬ì¡° ë¶„ì„
        logger.info(f"ğŸ” API ì‘ë‹µ ë¶„ì„: result.results ê°œìˆ˜={len(result.results) if hasattr(result, 'results') and result.results else 0}")

        if not hasattr(result, 'results') or not result.results:
            logger.error("âš ï¸ result.resultsê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ")
            return {
                'status': 'error',
                'segments': [],
                'speakers': {},
                'transcript': '',
                'error': 'API ê²°ê³¼ì— results ì†ì„±ì´ ì—†ìŒ'
            }

        # ê° ê²°ê³¼ ì²˜ë¦¬
        for i, result_item in enumerate(result.results):
            alternative = result_item.alternatives[0] if result_item.alternatives else None

            logger.info(f"ğŸ” ê²°ê³¼ {i}: alternatives ê°œìˆ˜={len(result_item.alternatives) if result_item.alternatives else 0}")

            if not alternative:
                logger.warning(f"âš ï¸ ê²°ê³¼ {i}ì— alternativeê°€ ì—†ìŒ")
                continue

            # í™”ìë³„ ë‹¨ì–´ ì²˜ë¦¬
            current_speaker = None
            current_segment = None

            words_count = len(alternative.words) if alternative.words else 0
            logger.info(f"ğŸ” ê²°ê³¼ {i}: ë‹¨ì–´ ìˆ˜={words_count}")

            if words_count == 0:
                logger.warning(f"âš ï¸ ê²°ê³¼ {i}ì— ë‹¨ì–´ê°€ ì—†ìŒ")
                continue

            # í™”ìë¶„ë¦¬ ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë‹¨ì–´ì˜ ëª¨ë“  ì†ì„± í™•ì¸
            if i == 0 and alternative.words:
                first_word = alternative.words[0]
                word_attrs = [attr for attr in dir(first_word) if not attr.startswith('_')]
                logger.info(f"ğŸ¯ ì²« ë‹¨ì–´ì˜ ëª¨ë“  ì†ì„±: {word_attrs}")
                logger.info(f"ğŸ¯ speaker_tag ì¡´ì¬ ì—¬ë¶€: {'speaker_tag' in word_attrs}")
                if hasattr(first_word, 'speaker_tag'):
                    logger.info(f"ğŸ¯ ì²« ë‹¨ì–´ speaker_tag ê°’: {first_word.speaker_tag}")
                else:
                    logger.warning("ğŸš¨ speaker_tag ì†ì„±ì´ ì—†ìŒ - í™”ìë¶„ë¦¬ ì„¤ì • í™•ì¸ í•„ìš”")

            # ì²˜ìŒ ëª‡ ê°œ ë‹¨ì–´ì˜ speaker_tag í™•ì¸ (ë””ë²„ê¹…ìš©)
            for j, word in enumerate(alternative.words[:5]):
                speaker_tag = getattr(word, 'speaker_tag', None)
                word_attrs = [attr for attr in dir(word) if not attr.startswith('_')] if speaker_tag is None else []
                logger.info(f"ğŸ” ë‹¨ì–´ {j}: '{word.word}' speaker_tag={speaker_tag}" +
                           (f" ì†ì„±: {word_attrs}" if word_attrs else ""))

            for word_info in alternative.words:
                speaker_tag = getattr(word_info, 'speaker_tag', None)
                logger.debug(f"ë‹¨ì–´: {word_info.word}, speaker_tag: {speaker_tag}")

                if speaker_tag is None:
                    logger.warning(f"ë‹¨ì–´ '{word_info.word}'ì— speaker_tagê°€ ì—†ìŒ")
                    continue

                # í™”ì ë³€ê²½ ê°ì§€
                if speaker_tag != current_speaker:
                    # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
                    if current_segment:
                        segments.append(current_segment)

                    # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
                    current_speaker = speaker_tag
                    current_segment = {
                        'speaker_id': speaker_tag,
                        'text': word_info.word,
                        'start_time': word_info.start_time.total_seconds(),
                        'end_time': word_info.end_time.total_seconds(),
                        'confidence': word_info.confidence if hasattr(word_info, 'confidence') else 1.0,
                        'words': [word_info.word]
                    }

                    # í™”ì í†µê³„ ì—…ë°ì´íŠ¸
                    if speaker_tag not in speaker_stats:
                        speaker_stats[speaker_tag] = {
                            'total_duration': 0,
                            'word_count': 0,
                            'segment_count': 0,
                            'avg_confidence': []
                        }
                    speaker_stats[speaker_tag]['segment_count'] += 1

                else:
                    # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì— ë‹¨ì–´ ì¶”ê°€
                    if current_segment:
                        current_segment['text'] += ' ' + word_info.word
                        current_segment['words'].append(word_info.word)
                        current_segment['end_time'] = word_info.end_time.total_seconds()

                # í™”ì í†µê³„ ì—…ë°ì´íŠ¸
                if speaker_tag in speaker_stats:
                    speaker_stats[speaker_tag]['word_count'] += 1
                    if hasattr(word_info, 'confidence'):
                        speaker_stats[speaker_tag]['avg_confidence'].append(word_info.confidence)

            # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
            if current_segment:
                segments.append(current_segment)

            # ì „ì²´ í…ìŠ¤íŠ¸
            full_transcript.append(alternative.transcript)

        # ì„¸ê·¸ë¨¼íŠ¸ í›„ì²˜ë¦¬
        for segment in segments:
            segment['duration'] = segment['end_time'] - segment['start_time']

        # í™”ì í†µê³„ ê³„ì‚°
        for speaker_id, stats in speaker_stats.items():
            stats['total_duration'] = sum(
                seg['duration'] for seg in segments if seg['speaker_id'] == speaker_id
            )
            stats['avg_confidence'] = np.mean(stats['avg_confidence']) if stats['avg_confidence'] else 1.0
            stats['speaking_rate'] = stats['word_count'] / max(stats['total_duration'], 1)

        # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        logger.info(f"í™”ìë¶„ë¦¬ ê²°ê³¼: segments={len(segments)}, speakers={len(speaker_stats)}")
        if len(segments) == 0:
            logger.warning("âš ï¸ í™”ìë¶„ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ!")
            logger.warning(f"ì „ì²´ ê²°ê³¼ ìˆ˜: {len(result.results)}")
            for i, result_item in enumerate(result.results):
                if result_item.alternatives:
                    alt = result_item.alternatives[0]
                    logger.warning(f"ê²°ê³¼ {i}: transcript='{alt.transcript}', words={len(alt.words)}")
                    if alt.words:
                        word_sample = alt.words[0]
                        logger.warning(f"ì²« ë²ˆì§¸ ë‹¨ì–´ ì†ì„±: {dir(word_sample)}")
                        logger.warning(f"speaker_tag ì¡´ì¬ì—¬ë¶€: {hasattr(word_sample, 'speaker_tag')}")

        return {
            'status': 'success',
            'segments': segments,
            'transcript': ' '.join(full_transcript),
            'speaker_stats': speaker_stats,
            'total_segments': len(segments),
            'total_speakers': len(speaker_stats)
        }

    def _validate_speaker_separation(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """í™”ì ë¶„ë¦¬ ê²°ê³¼ ê²€ì¦ ë° ë³´ì •"""

        segments = result.get('segments', [])
        speaker_stats = result.get('speaker_stats', {})

        # 1. ìµœì†Œ ë°œí™” ì‹œê°„ ì²´í¬ (ë„ˆë¬´ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©)
        MIN_SEGMENT_DURATION = 0.5  # 0.5ì´ˆ
        merged_segments = []

        for i, segment in enumerate(segments):
            if segment['duration'] < MIN_SEGMENT_DURATION and i > 0:
                # ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ì™€ ê°™ì€ í™”ìë©´ ë³‘í•©
                if merged_segments and merged_segments[-1]['speaker_id'] == segment['speaker_id']:
                    merged_segments[-1]['text'] += ' ' + segment['text']
                    merged_segments[-1]['end_time'] = segment['end_time']
                    merged_segments[-1]['duration'] = (
                        merged_segments[-1]['end_time'] - merged_segments[-1]['start_time']
                    )
                    merged_segments[-1]['words'].extend(segment.get('words', []))
                else:
                    merged_segments.append(segment)
            else:
                merged_segments.append(segment)

        # 2. í™”ì ê· í˜• ì²´í¬
        if len(speaker_stats) == 2:
            durations = [stats['total_duration'] for stats in speaker_stats.values()]
            ratio = min(durations) / max(durations) if max(durations) > 0 else 0

            # ë„ˆë¬´ ë¶ˆê· í˜•í•œ ê²½ìš° ê²½ê³ 
            if ratio < 0.1:
                logger.warning(f"í™”ì ê°„ ë°œí™” ì‹œê°„ ë¶ˆê· í˜• ê°ì§€: {ratio:.2%}")
                result['validation_warnings'] = result.get('validation_warnings', [])
                result['validation_warnings'].append('speaker_imbalance')

        # 3. ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§
        MIN_CONFIDENCE = 0.5
        filtered_segments = [
            seg for seg in merged_segments
            if seg.get('confidence', 1.0) >= MIN_CONFIDENCE
        ]

        # 4. í™”ì ì¼ê´€ì„± ì²´í¬ (ê¸‰ê²©í•œ í™”ì ì „í™˜ ê²€ì¦)
        for i in range(1, len(filtered_segments) - 1):
            prev_speaker = filtered_segments[i-1]['speaker_id']
            curr_speaker = filtered_segments[i]['speaker_id']
            next_speaker = filtered_segments[i+1]['speaker_id']

            # ë„ˆë¬´ ì§§ì€ ì¤‘ê°„ ë°œí™”ëŠ” ì˜ì‹¬
            if (prev_speaker == next_speaker and
                prev_speaker != curr_speaker and
                filtered_segments[i]['duration'] < 1.0):

                # í™”ì íƒœê·¸ ìˆ˜ì • ê³ ë ¤
                logger.debug(f"í™”ì ì¼ê´€ì„± ì˜ì‹¬ êµ¬ê°„ ê°ì§€: {i}ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸")

        result['segments'] = filtered_segments
        result['validation_status'] = 'validated'
        result['validation_confidence'] = self._calculate_overall_confidence(result)

        return result

    def _calculate_overall_confidence(self, result: Dict[str, Any]) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""

        segments = result.get('segments', [])
        if not segments:
            return 0.0

        # ì„¸ê·¸ë¨¼íŠ¸ ì‹ ë¢°ë„ ê°€ì¤‘ í‰ê·  (duration ê¸°ë°˜)
        total_duration = sum(seg['duration'] for seg in segments)
        if total_duration == 0:
            return 0.0

        weighted_confidence = sum(
            seg.get('confidence', 1.0) * seg['duration']
            for seg in segments
        )

        return weighted_confidence / total_duration

    async def _cleanup_storage(self, gs_uri: str):
        """ì„ì‹œ Storage íŒŒì¼ ì •ë¦¬"""
        try:
            if 'temp/' in gs_uri:
                # GCSì—ì„œ ì‚­ì œ
                bucket_name = gs_uri.split('/')[2]
                blob_name = '/'.join(gs_uri.split('/')[3:])

                bucket = self.storage_client.bucket(bucket_name)
                blob = bucket.blob(blob_name)
                blob.delete()

                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {gs_uri}")
        except Exception as e:
            logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")


class OpenAIConnector:
    """OpenAI GPT-4o API ì—°ë™"""

    def __init__(self, api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: OpenAI API í‚¤
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')

        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (1.51.0 ë™ê¸° ë²„ì „ ì‚¬ìš©)
        self.client = OpenAI(api_key=self.api_key)

        logger.info("OpenAI API ì—°ë™ ì´ˆê¸°í™” ì™„ë£Œ")

    async def analyze_text(
        self,
        text: str,
        context: Optional[Dict] = None,
        model: str = "gpt-4o"
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê°ì • ë° ì˜ë¯¸ ë¶„ì„

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            model: ì‚¬ìš©í•  ëª¨ë¸

        Returns:
            ë¶„ì„ ê²°ê³¼
        """

        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = self._build_system_prompt()

            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = self._build_user_prompt(text, context)

            # API í˜¸ì¶œ
            # ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            import asyncio
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"}
                )
            )

            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response.choices[0].message.content)

            return {
                'status': 'success',
                'analysis': result,
                'model': model,
                'usage': {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens,
                    'total_tokens': response.usage.total_tokens
                }
            }

        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'analysis': {}
            }

    def _build_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        return """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì •ì‹ ê±´ê°• ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì§€í‘œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
        1. DRI (ìš°ìš¸ ìœ„í—˜ ì§€ìˆ˜): ìš°ìš¸ì¦ ê´€ë ¨ ì–¸ì–´ íŒ¨í„´
        2. SDI (ìˆ˜ë©´ ì¥ì•  ì§€ìˆ˜): ìˆ˜ë©´ ë¬¸ì œ ê´€ë ¨ í‘œí˜„
        3. CFL (ì¸ì§€ ê¸°ëŠ¥ ìˆ˜ì¤€): ì¸ì§€ ëŠ¥ë ¥ ë° ì–¸ì–´ êµ¬ì„±ë ¥
        4. ES (ì •ì„œ ì•ˆì •ì„±): ê°ì • ë³€í™” ë° ì•ˆì •ì„±
        5. OV (ì „ë°˜ì  í™œë ¥): ì—ë„ˆì§€ ë° í™œë™ì„±

        ê° ì§€í‘œëŠ” 0-1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ë©°, ë†’ì„ìˆ˜ë¡ ê¸ì •ì ì…ë‹ˆë‹¤.

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {
            "indicators": {
                "DRI": 0.0-1.0,
                "SDI": 0.0-1.0,
                "CFL": 0.0-1.0,
                "ES": 0.0-1.0,
                "OV": 0.0-1.0
            },
            "sentiment": {
                "positive": 0.0-1.0,
                "negative": 0.0-1.0,
                "neutral": 0.0-1.0
            },
            "emotions": {
                "joy": 0.0-1.0,
                "sadness": 0.0-1.0,
                "anger": 0.0-1.0,
                "fear": 0.0-1.0,
                "surprise": 0.0-1.0
            },
            "key_topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
            "concerns": ["ìš°ë ¤ì‚¬í•­1", "ìš°ë ¤ì‚¬í•­2"],
            "coherence_score": 0.0-1.0,
            "interpretation": "ì¢…í•© í•´ì„"
        }"""

    def _build_user_prompt(self, text: str, context: Optional[Dict]) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt = f"ë‹¤ìŒ ì‹œë‹ˆì–´ì˜ ë°œí™”ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{text}"

        if context:
            prompt += f"\n\nì¶”ê°€ ì •ë³´:\n"
            if context.get('age'):
                prompt += f"- ì—°ë ¹: {context['age']}ì„¸\n"
            if context.get('gender'):
                prompt += f"- ì„±ë³„: {context['gender']}\n"
            if context.get('previous_analysis'):
                prompt += f"- ì´ì „ ë¶„ì„ ê¸°ë¡ ìˆìŒ\n"

        return prompt


class XAIConnector:
    """XAI (Grok) API ì—°ë™"""

    def __init__(self, api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: XAI API í‚¤
        """
        self.api_key = api_key or os.getenv('XAI_API_KEY')
        self.base_url = "https://api.x.ai/v1"
        self.model = "grok-4-0709"

        if not self.api_key:
            logger.warning("XAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤ - OpenAIë¡œ fallbackë©ë‹ˆë‹¤")
            self.client = None
        else:
            from openai import AsyncOpenAI
            self.client = AsyncOpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            logger.info("XAI (Grok) API ì—°ë™ ì´ˆê¸°í™” ì™„ë£Œ")

    async def analyze_text(
        self,
        text: str,
        context: Optional[Dict] = None,
        model: str = "grok-4-0709"
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê°ì • ë° ì˜ë¯¸ ë¶„ì„

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            model: ì‚¬ìš©í•  ëª¨ë¸

        Returns:
            ë¶„ì„ ê²°ê³¼
        """

        if not self.client:
            raise ValueError("XAI APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = self._build_system_prompt()

            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = self._build_user_prompt(text, context)

            # API í˜¸ì¶œ
            # ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
            import asyncio
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"}
                )
            )

            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response.choices[0].message.content)

            return {
                'status': 'success',
                'analysis': result,
                'model': model,
                'provider': 'xai',
                'usage': {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens,
                    'total_tokens': response.usage.total_tokens
                }
            }

        except Exception as e:
            logger.error(f"XAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise  # ìƒìœ„ì—ì„œ fallback ì²˜ë¦¬

    def _build_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        return """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì •ì‹ ê±´ê°• ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì§€í‘œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
        1. DRI (ìš°ìš¸ ìœ„í—˜ ì§€ìˆ˜): ìš°ìš¸ì¦ ê´€ë ¨ ì–¸ì–´ íŒ¨í„´
        2. SDI (ìˆ˜ë©´ ì¥ì•  ì§€ìˆ˜): ìˆ˜ë©´ ë¬¸ì œ ê´€ë ¨ í‘œí˜„
        3. CFL (ì¸ì§€ ê¸°ëŠ¥ ìˆ˜ì¤€): ì¸ì§€ ëŠ¥ë ¥ ë° ì–¸ì–´ êµ¬ì„±ë ¥
        4. ES (ì •ì„œ ì•ˆì •ì„±): ê°ì • ë³€í™” ë° ì•ˆì •ì„±
        5. OV (ì „ë°˜ì  í™œë ¥): ì—ë„ˆì§€ ë° í™œë™ì„±

        ê° ì§€í‘œëŠ” 0-1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ë©°, ë†’ì„ìˆ˜ë¡ ê¸ì •ì ì…ë‹ˆë‹¤.

        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {
            "indicators": {
                "DRI": 0.0-1.0,
                "SDI": 0.0-1.0,
                "CFL": 0.0-1.0,
                "ES": 0.0-1.0,
                "OV": 0.0-1.0
            },
            "sentiment": {
                "positive": 0.0-1.0,
                "negative": 0.0-1.0,
                "neutral": 0.0-1.0
            },
            "emotions": {
                "joy": 0.0-1.0,
                "sadness": 0.0-1.0,
                "anger": 0.0-1.0,
                "fear": 0.0-1.0,
                "surprise": 0.0-1.0
            },
            "key_topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
            "concerns": ["ìš°ë ¤ì‚¬í•­1", "ìš°ë ¤ì‚¬í•­2"],
            "coherence_score": 0.0-1.0,
            "interpretation": "ì¢…í•© í•´ì„"
        }"""

    def _build_user_prompt(self, text: str, context: Optional[Dict]) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt = f"ë‹¤ìŒ ì‹œë‹ˆì–´ì˜ ë°œí™”ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{text}"

        if context:
            prompt += f"\n\nì¶”ê°€ ì •ë³´:\n"
            if context.get('age'):
                prompt += f"- ì—°ë ¹: {context['age']}ì„¸\n"
            if context.get('gender'):
                prompt += f"- ì„±ë³„: {context['gender']}\n"
            if context.get('previous_analysis'):
                prompt += f"- ì´ì „ ë¶„ì„ ê¸°ë¡ ìˆìŒ\n"

        return prompt


class GeminiConnector:
    """Google Gemini API ì—°ë™"""

    def __init__(self, api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            api_key: Google Gemini API í‚¤
        """
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')

        if not self.api_key:
            logger.warning("Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤ - OpenAIë¡œ fallbackë©ë‹ˆë‹¤")
            self.client = None
        else:
            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel('gemini-2.0-flash-exp')
            logger.info("Gemini API ì—°ë™ ì´ˆê¸°í™” ì™„ë£Œ")

    async def analyze_text(
        self,
        text: str,
        context: Optional[Dict] = None,
        model: str = "gemini-2.0-flash-exp"
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê°ì • ë° ì˜ë¯¸ ë¶„ì„

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            model: ì‚¬ìš©í•  ëª¨ë¸

        Returns:
            ë¶„ì„ ê²°ê³¼
        """

        if not self.client:
            raise ValueError("Gemini APIê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = self._build_system_prompt()

            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = self._build_user_prompt(text, context)

            # ì „ì²´ í”„ë¡¬í”„íŠ¸ ì¡°í•©
            full_prompt = f"{system_prompt}\n\n{user_prompt}"

            # Gemini API í˜¸ì¶œ
            response = await asyncio.to_thread(
                self.client.generate_content,
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.3,
                    max_output_tokens=2000,
                )
            )

            # ì‘ë‹µ íŒŒì‹±
            try:
                result = json.loads(response.text)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ ì‹œë„
                result = self._extract_json_from_text(response.text)

            return {
                'status': 'success',
                'analysis': result,
                'model': model,
                'provider': 'gemini',
                'usage': {
                    'prompt_tokens': len(full_prompt.split()),
                    'completion_tokens': len(response.text.split()),
                    'total_tokens': len(full_prompt.split()) + len(response.text.split())
                }
            }

        except Exception as e:
            logger.error(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise  # ìƒìœ„ì—ì„œ fallback ì²˜ë¦¬

    def _build_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        return """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì •ì‹ ê±´ê°• ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì§€í‘œë“¤ì„ í‰ê°€í•´ì£¼ì„¸ìš”:
1. DRI (ìš°ìš¸ ìœ„í—˜ ì§€ìˆ˜): ìš°ìš¸ì¦ ê´€ë ¨ ì–¸ì–´ íŒ¨í„´
2. SDI (ìˆ˜ë©´ ì¥ì•  ì§€ìˆ˜): ìˆ˜ë©´ ë¬¸ì œ ê´€ë ¨ í‘œí˜„
3. CFL (ì¸ì§€ ê¸°ëŠ¥ ìˆ˜ì¤€): ì¸ì§€ ëŠ¥ë ¥ ë° ì–¸ì–´ êµ¬ì„±ë ¥
4. ES (ì •ì„œ ì•ˆì •ì„±): ê°ì • ë³€í™” ë° ì•ˆì •ì„±
5. OV (ì „ë°˜ì  í™œë ¥): ì—ë„ˆì§€ ë° í™œë™ì„±

ê° ì§€í‘œëŠ” 0-1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ í‰ê°€í•˜ë©°, ë†’ì„ìˆ˜ë¡ ê¸ì •ì ì…ë‹ˆë‹¤.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
    "indicators": {
        "DRI": 0.0-1.0,
        "SDI": 0.0-1.0,
        "CFL": 0.0-1.0,
        "ES": 0.0-1.0,
        "OV": 0.0-1.0
    },
    "sentiment": {
        "positive": 0.0-1.0,
        "negative": 0.0-1.0,
        "neutral": 0.0-1.0
    },
    "emotions": {
        "joy": 0.0-1.0,
        "sadness": 0.0-1.0,
        "anger": 0.0-1.0,
        "fear": 0.0-1.0,
        "surprise": 0.0-1.0
    },
    "key_topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
    "concerns": ["ìš°ë ¤ì‚¬í•­1", "ìš°ë ¤ì‚¬í•­2"],
    "coherence_score": 0.0-1.0,
    "interpretation": "ì¢…í•© í•´ì„"
}"""

    def _build_user_prompt(self, text: str, context: Optional[Dict]) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        prompt = f"ë‹¤ìŒ ì‹œë‹ˆì–´ì˜ ë°œí™”ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{text}"

        if context:
            prompt += f"\n\nì¶”ê°€ ì •ë³´:\n"
            if context.get('age'):
                prompt += f"- ì—°ë ¹: {context['age']}ì„¸\n"
            if context.get('gender'):
                prompt += f"- ì„±ë³„: {context['gender']}\n"
            if context.get('previous_analysis'):
                prompt += f"- ì´ì „ ë¶„ì„ ê¸°ë¡ ìˆìŒ\n"

        return prompt

    def _extract_json_from_text(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ"""
        try:
            # JSON ë¸”ë¡ ì°¾ê¸°
            import re
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                # ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
                return {
                    "indicators": {
                        "DRI": 0.5, "SDI": 0.5, "CFL": 0.5, "ES": 0.5, "OV": 0.5
                    },
                    "sentiment": {"positive": 0.3, "negative": 0.3, "neutral": 0.4},
                    "emotions": {
                        "joy": 0.2, "sadness": 0.2, "anger": 0.1, "fear": 0.1, "surprise": 0.1
                    },
                    "key_topics": ["ì¼ë°˜ì  ëŒ€í™”"],
                    "concerns": [],
                    "coherence_score": 0.7,
                    "interpretation": "JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ê°’"
                }
        except:
            return {
                "indicators": {
                    "DRI": 0.5, "SDI": 0.5, "CFL": 0.5, "ES": 0.5, "OV": 0.5
                },
                "sentiment": {"positive": 0.3, "negative": 0.3, "neutral": 0.4},
                "emotions": {
                    "joy": 0.2, "sadness": 0.2, "anger": 0.1, "fear": 0.1, "surprise": 0.1
                },
                "key_topics": ["íŒŒì‹± ì˜¤ë¥˜"],
                "concerns": [],
                "coherence_score": 0.5,
                "interpretation": "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
            }


class MultiLLMConnector:
    """ë‹¤ì¤‘ LLM API ì—°ë™ (Gemini 1ìˆœìœ„, OpenAI 2ìˆœìœ„, XAI 3ìˆœìœ„)"""

    def __init__(self, gemini_api_key: Optional[str] = None, openai_api_key: Optional[str] = None, xai_api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            gemini_api_key: Gemini API í‚¤ (1ìˆœìœ„)
            openai_api_key: OpenAI API í‚¤ (2ìˆœìœ„)
            xai_api_key: XAI API í‚¤ (3ìˆœìœ„)
        """
        # Gemini ì»¤ë„¥í„° ì´ˆê¸°í™” (1ìˆœìœ„)
        try:
            self.gemini_connector = GeminiConnector(gemini_api_key)
            self.gemini_available = self.gemini_connector.client is not None
        except Exception as e:
            logger.warning(f"Gemini ì»¤ë„¥í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.gemini_connector = None
            self.gemini_available = False

        # OpenAI ì»¤ë„¥í„° ì´ˆê¸°í™” (2ìˆœìœ„)
        try:
            self.openai_connector = OpenAIConnector(openai_api_key)
            self.openai_available = self.openai_connector.client is not None
        except Exception as e:
            logger.warning(f"OpenAI ì»¤ë„¥í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.openai_connector = None
            self.openai_available = False

        # XAI ì»¤ë„¥í„° ì´ˆê¸°í™” (3ìˆœìœ„)
        try:
            self.xai_connector = XAIConnector(xai_api_key)
            self.xai_available = self.xai_connector.client is not None
        except Exception as e:
            logger.warning(f"XAI ì»¤ë„¥í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.xai_connector = None
            self.xai_available = False

        # ì‚¬ìš© ê°€ëŠ¥í•œ API ì²´í¬
        if not self.gemini_available and not self.openai_available and not self.xai_available:
            raise ValueError("Gemini, OpenAI, XAI API ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        logger.info(f"MultiLLM ì´ˆê¸°í™” ì™„ë£Œ - Gemini: {self.gemini_available}, OpenAI: {self.openai_available}, XAI: {self.xai_available}")

    async def analyze_text(
        self,
        text: str,
        context: Optional[Dict] = None,
        force_model: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ë¶„ì„ (Gemini 1ìˆœìœ„, OpenAI 2ìˆœìœ„, XAI 3ìˆœìœ„)

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            force_model: ê°•ì œ ì‚¬ìš© ëª¨ë¸ ('gemini', 'openai', 'xai')

        Returns:
            ë¶„ì„ ê²°ê³¼
        """

        # íŠ¹ì • ëª¨ë¸ ê°•ì œ ì‚¬ìš©
        if force_model:
            if force_model == 'gemini' and self.gemini_available:
                logger.info("Gemini ê°•ì œ ì‚¬ìš© ëª¨ë“œ")
                return await self.gemini_connector.analyze_text(text, context)
            elif force_model == 'openai' and self.openai_available:
                logger.info("OpenAI ê°•ì œ ì‚¬ìš© ëª¨ë“œ")
                return await self.openai_connector.analyze_text(text, context)
            elif force_model == 'xai' and self.xai_available:
                logger.info("XAI ê°•ì œ ì‚¬ìš© ëª¨ë“œ")
                return await self.xai_connector.analyze_text(text, context)

        # Gemini ìš°ì„  ì‹œë„ (1ìˆœìœ„)
        if self.gemini_available:
            try:
                logger.info("Gemini API ì‹œë„ ì¤‘...")
                result = await self.gemini_connector.analyze_text(text, context)
                logger.info("Gemini API ì„±ê³µ")
                return result

            except Exception as e:
                logger.warning(f"Gemini API ì‹¤íŒ¨, OpenAIë¡œ fallback: {e}")

                # OpenAI fallback (2ìˆœìœ„)
                if self.openai_available:
                    try:
                        logger.info("OpenAI API fallback ì‹œë„ ì¤‘...")
                        result = await self.openai_connector.analyze_text(text, context)
                        result['fallback_used'] = True
                        result['fallback_reason'] = str(e)
                        logger.info("OpenAI API fallback ì„±ê³µ")
                        return result
                    except Exception as openai_error:
                        logger.warning(f"OpenAI fallback ì‹¤íŒ¨, XAIë¡œ ì‹œë„: {openai_error}")

                        # XAI fallback (3ìˆœìœ„)
                        if self.xai_available:
                            try:
                                logger.info("XAI API fallback ì‹œë„ ì¤‘...")
                                result = await self.xai_connector.analyze_text(text, context)
                                result['fallback_used'] = True
                                result['fallback_level'] = 2
                                result['fallback_reason'] = f"Gemini: {e}, OpenAI: {openai_error}"
                                logger.info("XAI API fallback ì„±ê³µ")
                                return result
                            except Exception as xai_error:
                                logger.error(f"ëª¨ë“  API ì‹¤íŒ¨: Gemini: {e}, OpenAI: {openai_error}, XAI: {xai_error}")
                                return self._get_error_response(f"ëª¨ë“  API ì‹¤íŒ¨")
                        else:
                            return self._get_error_response(f"Gemini/OpenAI ì‹¤íŒ¨, XAI ì‚¬ìš© ë¶ˆê°€")
                else:
                    return self._get_error_response(f"Gemini ì‹¤íŒ¨, OpenAI ì‚¬ìš© ë¶ˆê°€: {e}")

        # Gemini ì‚¬ìš© ë¶ˆê°€ì‹œ OpenAI ì‚¬ìš© (2ìˆœìœ„)
        elif self.openai_available:
            logger.info("Gemini ì‚¬ìš© ë¶ˆê°€, OpenAI ì‚¬ìš©")
            try:
                result = await self.openai_connector.analyze_text(text, context)
                result['gemini_unavailable'] = True
                return result
            except Exception as e:
                logger.warning(f"OpenAI ì‹¤íŒ¨, XAIë¡œ fallback: {e}")
                if self.xai_available:
                    try:
                        result = await self.xai_connector.analyze_text(text, context)
                        result['fallback_used'] = True
                        return result
                    except Exception as xai_error:
                        return self._get_error_response(f"OpenAI/XAI ëª¨ë‘ ì‹¤íŒ¨")

        # XAIë§Œ ì‚¬ìš© ê°€ëŠ¥ (3ìˆœìœ„)
        elif self.xai_available:
            logger.info("Gemini/OpenAI ì‚¬ìš© ë¶ˆê°€, XAIë§Œ ì‚¬ìš©")
            result = await self.xai_connector.analyze_text(text, context)
            result['only_xai'] = True
            return result

        else:
            return self._get_error_response("ì‚¬ìš© ê°€ëŠ¥í•œ APIê°€ ì—†ìŠµë‹ˆë‹¤")

    def _get_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            'status': 'error',
            'error': error_message,
            'analysis': {
                "indicators": {
                    "DRI": 0.5, "SDI": 0.5, "CFL": 0.5, "ES": 0.5, "OV": 0.5
                },
                "sentiment": {"positive": 0.3, "negative": 0.3, "neutral": 0.4},
                "emotions": {
                    "joy": 0.2, "sadness": 0.2, "anger": 0.1, "fear": 0.1, "surprise": 0.1
                },
                "key_topics": ["API ì˜¤ë¥˜"],
                "concerns": ["API ì—°ê²° ì‹¤íŒ¨"],
                "coherence_score": 0.0,
                "interpretation": f"API ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ê°’: {error_message}"
            }
        }
